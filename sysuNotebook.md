# (Note)Learning Semantic-Specific Graph Representation for Multi-Label Image Recognition
  
原文链接：
[https://arxiv.org/pdf/1908.07325.pdf](https://arxiv.org/pdf/1908.07325.pdf)

目前还不清楚内涵的关键词：
1. multi-label recognition
2. semantic-aware
3. decoupling
4. 图表示学习

先搞清楚这些基本概念吧。
##### 多标签分类
找到一篇综述：
https://www.cnblogs.com/cxf-zzj/p/10049613.html

多标签的需求：以文章分类举例，一篇文章既可以属于“经济”也可以属于“文化”。
难点：
- 一个entity(不知道可不可以用这个单词形容)对应的类标数量相差巨大，可能对应1个也可能对应几百个
- 类标之间的相互依赖/耦合？
- 难以获取训练集，老生常谈了

解决方法：两大类(看起来没有啥特别针对的算法？)
1. 基于问题转化的方法
   1. 最简单的：单标签预测
   2. 要考虑关联性的话，用分类器链或者时序(前一个的out是后一个的in)
   3. 或者标签组合(但是根本没法用在标签维度高的情况下)
2. 基于算法适用的方法
   1. 主要是改造算法，似乎在深度学习领域会用到注意力机制，论文中的semantic-aware应该也是差不多的意思

##### semantic-aware
应该是用到了语义的这种“注意力”的机制，接着看下去应该就清楚了
##### decoupling
就是解耦吧
##### 图表示学习
之前一直没认真了解过图这方面的结构

参考：
https://zhuanlan.zhihu.com/p/85677181

图学习的作用：
节点分类，链接预测，社群检测，网络相似度
- Embedding: 一个样本的特征向量，不管它是否来自一个训练的网络，或是来自其他方法的构造，我们都可称之为Embedding。因为我们的最终目标是迭代出最优的特征向量，蕴含相似度信息，所以我们把这种特征向量也称之为Embedding.
难点在于抽取图结构数据的特征。
所以说所谓图学习的关键似乎在于如何高效地将输入数据(即图结构，nodes)映射到特征向量，并在这个过程中保留尽可能丰富的拓扑信息(所以叫"表示学习"?)
- 图表示学习的目标就是用n个向量表示图上的n个结点，这样就可以将一个难以表达的拓扑结构转化为可以丢进炼丹炉的 vector！
1. 图结构表示学习
   - Node2vec：单个节点到邻居节点跳跃的概率是不同的(有点像强化学习的马尔科夫链？)
   BFS: 宽度优先；DFS: 深度优先

2. 图特征表示学习
   - GCN：“结点i在下一层的表示是由其所有邻居节点j所构成的集合Neighbor(i)来决定的”，邻居结点的聚合。
   - GraphSAGE：只选择S个邻居节点进行聚合，有点像dropout，增加可计算性
   - GAT：加了注意力机制。(ps:论文公式中的||是concat操作)

论文中文译文参考：https://blog.csdn.net/weixin_43436958/article/details/111564594
#### Abstract： 
[Q1]
语义解耦模块和语义交互模块？一个实体所对应的标签之间是可能具有潜在联系的。挖掘标签的这种语义信息可能会对提高分类精度有益，但是听起来有点玄乎

[A1]
**看了后面的论文，大概懂训练的流程了。实际上所谓的语义解耦就是将类别词用Glove模型扩充到蕴含更多上下文信息的词向量，再用这个低秩双线性池化来融合图像特征和词向量最后加权，类似于按照不同权重同时学习多个类别标签**
#### Introduction：
**我们首先设计一个语义解耦模块，该模块利用类别的语义特征来指导学习与类别相关的图像特征，这些图像特征更加关注相应的语义区域。然后，我们构建一个基于统计标签共现的图来关联这些特征，并通过图传播机制来探索它们之间的相互作用**

#### Related Works：
提炼一下：最近多标签分类的进展多在于引入了对象定位，产生候选区域proposal(类比Faster-RCNN)，使得它可以注意到图像的各个子区域，分别进行预测，但是候选区域的产生和筛选难以被端到端训练

[Q1]
感觉和Faster-RCNN这些目标检测极其相似。。。那这么说，多标签图像分类完全没必要啊，因为它完全可以用目标检测模型来做不是吗???那为啥要搞得这么麻烦.....

[A1]**懂了，还是有区别的。图像分类毕竟是分类，数据集中标签只需要给出图像对应的类别就行，而不需要像目标检测一样给出BBox标定。目标检测确实是多标签图像分类的上位，但是他要的训练集成本也高得多，因此，设计一个只需要常规的图像分类数据集却能够接近目标检测那样多类检测的效果的模型，还是很有意义的**

也有用注意力机制来定位区域的，但是定位不精确.

或者也可以利用标签的依赖关系来建模(应该和作者的方法属于同一类的)，LSTM和RNN这种具有序列关系预测功能的网络就可以办到，但是并不能完全利用该特性(可能是因为他们只能按照时序?)

#### SSGRL Framework:
1. Overview

   关键：1、对于每个类别，语义解耦模块结合类别语义来指导学习特定于语义的表示
   2、语义交互模块使用基于统计标签共现构建的图来关联这些表示。

2. Semantic Decoupling:

   [Q1]
   这一部分的：
   >For each category c, the framework extracts a ds-dimensional semantic-embedding vector using the pre-trained GloVe model

   这个d维语义embedding vector是怎么来的？不能理解这里的fg是指代什么。wc是所谓“c类别对应的semantic word”，这里也没搞清楚

   [A1]
   **稍微懂一点了。这里是单独处理类别对应的词，用Glove模型训练出来一个对应的语义向量，赋予其语义信息。比如说输入car，返回它的向量，而这个向量又和track,bus,train等类似。等于说赋予标签以语义信息。**

   概括：这一步提取了1、图像的特征；2、该图像对应类别的词嵌入向量  然后用低秩双线性池化将他们融合，并通过一个全连接网络计算他们的注意系数。最后对这些注意系数进行归一化，并与上面的融合后的特征求加权平均。

   [Q2]
   低秩双线性池化?

   [A2]
   https://zhuanlan.zhihu.com/p/62532887

   是一种特征融合的手段
   原始的Bilinear Pooling存在融合后的特征维数过高的问题，融合后的特征维数=特征x和特征y的维数之积。
   改进：LRBP：Low-rank Bilinear Pooling
   怎么说，有点像是求两个特征的gram matrix, which is used in neural style transfer.


3. Semantic Interaction

   引入图G，其中节点指的是类别，边指的是对应类别之间的共现概率。
   每个节点可以聚集来自其他节点的消息，并同时通过图传递其信息，从而能够在对应于所有类别的所有特征向量之间进行交互,该过程重复T次，生成最终的隐藏状态。这样就可以学习一个各类别之间相关信息的隐藏表示了
   论文在这里将图结构写作{V,A}，V表示不同的类别词{v0,v1,v2…,v(c-1)}，A表示在c类别存在的条件下，c’类别存在的概率，A表示为{a00,a01,a02…,a0(c-1),…a(c-1)(c-1)}。

   https://blog.csdn.net/qq_45603919/article/details/109126254

   👆这篇文章在图网络这部分讲的很详细，省下不少时间。

   隐藏状态：将某个结点周围的信息融合成一个向量表示，因此可以用上一步生成的特征向量来初始化这个隐藏状态。
   特征聚合向量：某个类别对应的隐藏状态和两个共现概率的加权和。





4. Network Structure
   fcnn是ResNet-101,改了最后一个平均池化层

5. Optimization
















## 一级
### 二级
#### 三级

---
分割线

---

**加粗**
或者
__这样也行__
*斜体*
~~删除~~
<u>下划线</u>

<mark>文本高亮<mark>
正文

[链接](www.baidu.com)

```cpp
printf("Hi, you!");
```
正文中的代码``helllo``

有序列表
1. hello
2. i
3. am
4. hhx
   1. and
   2. i
      1. am
      2. here 
      3. to
         1. assist
         2. you.

无序列表
- item1
- item2
- item3

>   引用：操作系统的一些知识

